#!/usr/bin/env python3
"""
round_robin_stats.py â”€ Roundâ€‘robin tournament evaluator with statistics & plotting
====================================================================
> **æ›´æ–°**ï¼šæ”¹ä»¥ **`model_paths` æ‰‹å‹•æ¸…å–®**ï¼Œä¸å†è‡ªå‹•åµæ¸¬è¬ç”¨å­—å…ƒã€‚
>   â€‘ ä½¿ç”¨è€…å¯åœ¨ `USER_CONFIG` å¡«å…¥ä»»æ„æª”æ¡ˆè·¯å¾‘ listã€‚  
>   â€‘ å…¶é¤˜åŠŸèƒ½ (çµ±è¨ˆ / åœ–è¡¨) ä¸è®Šã€‚

åŠŸèƒ½ä¸€è¦½
---------
1. **çµ±è¨ˆæ‰€æœ‰å°æˆ°è³‡æ–™ã€å‹çŽ‡**  â†’ `match_records.csv`, `summary.csv`
2. **æ¼‚äº®åœ–è¡¨**                 â†’ `win_rates.png`, `h2h_heatmap.png`
3. **æ˜“èª¿æ•´ä»‹é¢ & ä¸­æ–‡è¨»è§£**      â†’ é€šé€šé›†ä¸­åœ¨ `USER_CONFIG`  å€å¡Š

åŽŸå§‹ä¾†æºï¼š`test_round.py`  (ä½¿ç”¨è€…ä¸Šå‚³)  îˆ€citeîˆ‚turn0file0îˆ
"""
from __future__ import annotations

import itertools
from pathlib import Path
from typing import Dict, List, Tuple

import yaml
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from envs.my_pong_env_2p import PongEnv2P  # type: ignore
from models.qnet import QNet  # type: ignore

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                         USER CONFIG                             â•‘
# â•‘   ðŸ‘‡ðŸ‘‡ðŸ‘‡ åªæ”¹é€™è£¡å°±è¡Œï¼                                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USER_CONFIG = {
    # YAML æª”ï¼šç’°å¢ƒè¨­å®š
    "config_yaml": "config.yaml",

    # âžœ æ‰‹å‹•åˆ—å‡ºæ‰€æœ‰æ¨¡åž‹
    "model_paths": [
        "checkpoints/model_gen1.pth",
        "checkpoints/model_gen3.pth",
        "checkpoints/model_gen5.pth",
        "checkpoints/model2_gen0.pth",
        "checkpoints/model2_gen1.pth",
        "checkpoints/model2_gen3.pth",
        "checkpoints/model2_gen5.pth",
        "checkpoints/model3_gen0.pth",
        "checkpoints/model3_gen3.pth",
        "checkpoints/model3_gen4.pth",
        "checkpoints/model4_gen0.pth",
    ],

    # æ¯å…©äººå°æˆ°çš„å±€æ•¸
    "episodes_each": 100,

    # çµæžœè¼¸å‡ºè³‡æ–™å¤¾
    "output_dir": "results",

    # æ˜¯å¦ç”¢ç”Ÿåœ–è¡¨ (PNG)
    "generate_plots": True,

    # æ˜¯å¦éœéŸ³ï¼ˆä¸é¡¯ç¤ºæ¯çµ„å°æˆ° logï¼‰
    "quiet": False,
}
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ----------------------------- å·¥å…·å‡½å¼ -----------------------------

def load_model(model_path: str | Path, device: torch.device) -> QNet:
    """Load a QNet checkpoint and return the model in eval mode."""
    path = Path(model_path)
    if not path.exists():
        raise FileNotFoundError(path)
    ckpt = torch.load(path, map_location=device)
    net = QNet(input_dim=7, output_dim=3).to(device)
    try:
        net.load_state_dict(ckpt["model"])
    except KeyError as e:
        raise KeyError(f"Checkpoint {path} missing 'model' key â†’ {e}")
    net.eval()
    return net

def select_action_eval(obs: np.ndarray, model: QNet, device: torch.device) -> int:
    """Greedy action selection (no exploration)."""
    with torch.no_grad():
        obs_t = torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)
        q = model(obs_t)
        action = int(q.argmax(dim=1).item())
    return action

# ---------------------------- ä¸» tournament ----------------------------

def round_robin(
    env_cfg: Dict,
    model_paths: List[str],
    episodes_each: int,
    device: torch.device,
    verbose: bool = True,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Run roundâ€‘robin tournament and return (match_df, summary_df)."""
    # 1. æº–å‚™é¸æ‰‹ (name â†’ model)
    participants: Dict[str, Dict] = {
        Path(p).stem: {"model": load_model(p, device)} for p in model_paths
    }

    # 2. å»ºç«‹ç’°å¢ƒ (çµ±ä¸€é—œé–‰ render)
    # å¼·åˆ¶é—œé–‰ renderï¼Œé¿å… YAML å…§å·²ç¶“å¸¶æœ‰åŒååƒæ•¸é€ æˆé‡è¤‡
    env_cfg["enable_render"] = False
    env = PongEnv2P(**env_cfg)

    match_records: List[Dict] = []

    # 3. æ¯å…©äººäº’æ‰“
    for a, b in itertools.combinations(participants.keys(), 2):
        net_a, net_b = participants[a]["model"], participants[b]["model"]
        wins_a = wins_b = 0
        for ep in range(episodes_each):
            obs_a, obs_b = env.reset()
            done = False
            score_a = score_b = 0
            while not done:
                act_a = select_action_eval(obs_a, net_a, device)
                act_b = select_action_eval(obs_b, net_b, device)
                (obs_a, obs_b), (r_a, r_b), done, _ = env.step(act_a, act_b)
                score_a += r_a
                score_b += r_b
            # è¨˜éŒ„çµæžœ
            if score_a > score_b:
                wins_a += 1
                winner = a
            elif score_b > score_a:
                wins_b += 1
                winner = b
            else:
                winner = "draw"
            match_records.append(
                {
                    "episode": ep,
                    "player_a": a,
                    "player_b": b,
                    "score_a": score_a,
                    "score_b": score_b,
                    "winner": winner,
                }
            )
        if verbose:
            print(f"{a} vs {b} â†’ A_wins={wins_a:3}  B_wins={wins_b:3}")

    env.close()

    # 4. çµ±è¨ˆ
    match_df = pd.DataFrame(match_records)
    win_count = match_df[match_df["winner"] != "draw"].groupby("winner").size()
    lose_count = (
        match_df[match_df["winner"] != "draw"]
        .assign(loser=lambda d: np.where(d["winner"] == d["player_a"], d["player_b"], d["player_a"]))
        .groupby("loser")
        .size()
    )
    summary_df = pd.DataFrame({"win": win_count, "lose": lose_count}).fillna(0).astype(int)
    summary_df["games"] = summary_df["win"] + summary_df["lose"]
    summary_df["win_rate"] = summary_df["win"] / summary_df["games"]
    summary_df = summary_df.sort_values("win_rate", ascending=False)

    return match_df, summary_df

# ---------------------------- è¦–è¦ºåŒ– ----------------------------

def plot_win_rates(summary_df: pd.DataFrame, out_dir: Path) -> Path:
    fig, ax = plt.subplots(figsize=(8, 5))
    summary_df["win_rate"].plot.bar(ax=ax)
    ax.set_ylabel("Win Rate (%)")
    ax.set_ylim(0, 1)
    ax.set_title("Tournament Win Rates")
    ax.set_xticklabels(summary_df.index, rotation=45, ha="right")
    fig.tight_layout()
    out_path = out_dir / "win_rates.png"
    fig.savefig(out_path, dpi=200)
    plt.close(fig)
    return out_path


def plot_h2h_heatmap(match_df: pd.DataFrame, out_dir: Path) -> Path:
    players = sorted(set(match_df["player_a"]).union(match_df["player_b"]))
    h2h = pd.DataFrame(0, index=players, columns=players, dtype=int)
    for _, row in match_df.iterrows():
        if row["winner"] == "draw":
            continue
        winner = row["winner"]
        loser = row["player_b"] if winner == row["player_a"] else row["player_a"]
        h2h.loc[winner, loser] += 1
    fig, ax = plt.subplots(figsize=(6, 5))
    sns.heatmap(h2h, annot=True, fmt="d", cmap="viridis", ax=ax)
    ax.set_xlabel("Loser â†’")
    ax.set_ylabel("Winner â†’")
    ax.set_title("Headâ€‘toâ€‘Head Wins")
    fig.tight_layout()
    out_path = out_dir / "h2h_heatmap.png"
    fig.savefig(out_path, dpi=200)
    plt.close(fig)
    return out_path

# ------------------------------- Main -------------------------------

def main() -> None:
    # è®€å–ç’°å¢ƒè¨­å®š
    cfg_path = Path(USER_CONFIG["config_yaml"])
    with open(cfg_path, "r", encoding="utfâ€‘8") as f:
        env_cfg = yaml.safe_load(f)["env"]

    # è§£æž model list (æ‰‹å‹•æŒ‡å®š)
    model_paths = USER_CONFIG["model_paths"]
    if not model_paths:
        raise ValueError("USER_CONFIG['model_paths'] is empty. è«‹æ‰‹å‹•åˆ—å‡ºæ¨¡åž‹è·¯å¾‘ï¼")
    model_paths = [str(p) for p in model_paths]

    # å…¶ä»–åƒæ•¸
    episodes_each = int(USER_CONFIG["episodes_each"])
    output_dir = Path(USER_CONFIG["output_dir"])
    output_dir.mkdir(parents=True, exist_ok=True)
    generate_plots = bool(USER_CONFIG["generate_plots"])
    quiet = bool(USER_CONFIG["quiet"])

    # è£ç½®é¸æ“‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åŸ·è¡Œæ¯”è³½
    match_df, summary_df = round_robin(
        env_cfg=env_cfg,
        model_paths=model_paths,
        episodes_each=episodes_each,
        device=device,
        verbose=not quiet,
    )

    # å„²å­˜ CSV çµæžœ
    match_csv = output_dir / "match_records.csv"
    summary_csv = output_dir / "summary.csv"
    match_df.to_csv(match_csv, index=False)
    summary_df.to_csv(summary_csv)
    print(f"\n[âœ“] çµ±è¨ˆå®Œæˆ â†’ {summary_csv.resolve().relative_to(Path.cwd())}")

    # ç”¢ç”Ÿåœ–è¡¨
    if generate_plots:
        win_png = plot_win_rates(summary_df, output_dir)
        h2h_png = plot_h2h_heatmap(match_df, output_dir)
        print("[âœ“] åœ–è¡¨å·²ç”Ÿæˆ â†’", win_png.resolve().relative_to(Path.cwd()), ",", h2h_png.resolve().relative_to(Path.cwd()))

    # æŽ’åé¡¯ç¤º
    print("\n=== Final Ranking ===")
    for rank, (name, row) in enumerate(summary_df.itertuples(), 1):
        print(f"#{rank:>2}  {name:<25}  W:{row.win:>3}  L:{row.lose:>3}  WR:{row.win_rate*100:6.2f}%")


if __name__ == "__main__":
    main()

